{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjayBukka/Anti-Money-Laundering/blob/main/Group_Recommendation_Using_MutiCriteriaPreferences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "hCsrLgmHT6Jv",
        "outputId": "f8fed57c-92fa-48c0-da07-3ff59e79a227"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4f17cb9f42bf>\u001b[0m in \u001b[0;36m<cell line: 130>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-4f17cb9f42bf>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(dataset_path, target_cluster, group_size, c, m, max_iter)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mpreferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muser_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_user_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mpref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_preference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpref\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mpreferences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-4f17cb9f42bf>\u001b[0m in \u001b[0;36mcalculate_preference\u001b[0;34m(user_id, data)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_preference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0muser_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'User.ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Return None if user ID not found in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6095\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6096\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6098\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install scikit-fuzzy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import skfuzzy as fuzz\n",
        "from scipy.stats import pearsonr\n",
        "import os\n",
        "\n",
        "def read_dataset(dataset_path):\n",
        "    return pd.read_csv(dataset_path)\n",
        "\n",
        "def calculate_preference(user_id, data):\n",
        "    user_data = data[data['User.ID'] == user_id]\n",
        "    if user_data.empty:\n",
        "        return None  # Return None if user ID not found in the dataset\n",
        "\n",
        "    # Columns containing ratings\n",
        "    rating_columns = ['Value.Rating', 'Rooms.Rating', 'Location.Rating', 'Cleanliness.Rating',\n",
        "                      'Front.Desk.Rating', 'Service.Rating', 'Business.Service.Rating']\n",
        "\n",
        "    # Average ratings\n",
        "    average_ratings = data[rating_columns].mean()\n",
        "\n",
        "    # User's ratings\n",
        "    user_ratings = user_data[rating_columns].iloc[0]\n",
        "\n",
        "    # Calculate preferences\n",
        "    preferences = average_ratings - user_ratings\n",
        "\n",
        "    return preferences\n",
        "\n",
        "def normalize_preferences(preferences):\n",
        "    # Normalize the preferences using Min-Max scaling\n",
        "    min_pref = np.min(preferences)\n",
        "    max_pref = np.max(preferences)\n",
        "    return (preferences - min_pref) / (max_pref - min_pref)\n",
        "\n",
        "def perform_fuzzy_cmeans_clustering(normalized_preferences, c, m, max_iter):\n",
        "    # FCM clustering\n",
        "    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
        "        data=normalized_preferences.T, c=c, m=m, error=0.01, maxiter=max_iter, init=None\n",
        "    )\n",
        "\n",
        "    # Assign cluster labels to users\n",
        "    cluster_membership = np.argmax(u, axis=0)\n",
        "    return cluster_membership\n",
        "\n",
        "def filter_users_by_cluster(preferences, cluster_membership, target_cluster):\n",
        "    # Combine the user-item matrix with cluster labels\n",
        "    cluster_labaled_preferences = pd.concat([preferences, pd.DataFrame(cluster_membership, index=preferences.index, columns=[\"Cluster Label\"])], axis=1)\n",
        "\n",
        "    # Filter users from the target cluster\n",
        "    cluster_data = cluster_labaled_preferences[cluster_labaled_preferences[\"Cluster Label\"] == target_cluster]\n",
        "\n",
        "    # Delete the \"Cluster Label\" column\n",
        "    del cluster_data[\"Cluster Label\"]\n",
        "\n",
        "    return cluster_data\n",
        "\n",
        "def calculate_pcc(user1_preferences, user2_preferences):\n",
        "    # Convert to numpy arrays\n",
        "    x = np.array(user1_preferences)\n",
        "    y = np.array(user2_preferences)\n",
        "\n",
        "    # Calculate Pearson correlation coefficient\n",
        "    return pearsonr(x, y)[0] if len(x) == len(y) else None\n",
        "\n",
        "def select_top_similar_users(cluster_data, group_size):\n",
        "    # Select a random user from the cluster\n",
        "    random_user = np.random.choice(cluster_data.index.unique())\n",
        "\n",
        "    # Calculate PCC with the randomly selected user for all users in the same cluster\n",
        "    pcc_values = []\n",
        "\n",
        "    for user_id in cluster_data.index.unique():\n",
        "        if user_id != random_user:\n",
        "            user1_preferences = cluster_data.loc[random_user]\n",
        "            user2_preferences = cluster_data.loc[user_id]\n",
        "\n",
        "            pcc = calculate_pcc(user1_preferences, user2_preferences)\n",
        "            if pcc is not None:\n",
        "                pcc_values.append((user_id, pcc))\n",
        "\n",
        "    # Sort users by PCC values in descending order\n",
        "    pcc_values.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Extract the user IDs of the top similar users\n",
        "    similar_user_ids = [user_id for user_id, _ in pcc_values][:group_size]\n",
        "\n",
        "    # Create a new DataFrame containing data of the top similar users as a group\n",
        "    group_data = cluster_data.loc[similar_user_ids]\n",
        "\n",
        "    return group_data\n",
        "\n",
        "# Main function to orchestrate the entire process\n",
        "def main(dataset_path='/content/TripAdvisor_Filled.csv', target_cluster=1, group_size=5, c=3, m=50, max_iter=1000):\n",
        "    # Step 1: Read the dataset\n",
        "    data = read_dataset(dataset_path)\n",
        "\n",
        "    # Step 2: Get unique user IDs\n",
        "    unique_user_ids = data['User.ID'].unique()\n",
        "\n",
        "    # Step 3: Calculate preferences for each user\n",
        "    preferences = {}\n",
        "    for user_id in unique_user_ids:\n",
        "        pref = calculate_preference(user_id, data)\n",
        "        if pref is not None:\n",
        "            preferences[user_id] = pref\n",
        "    preferences_df = pd.DataFrame.from_dict(preferences, orient='index')\n",
        "\n",
        "    # Step 4: Normalize preferences\n",
        "    normalized_preferences = normalize_preferences(preferences_df)\n",
        "\n",
        "    # Step 5: Perform Fuzzy C-Means Clustering\n",
        "    cluster_membership = perform_fuzzy_cmeans_clustering(normalized_preferences, c, m, max_iter)\n",
        "\n",
        "    # Step 6: Filter users by cluster\n",
        "    cluster_data = filter_users_by_cluster(preferences_df, cluster_membership, target_cluster)\n",
        "\n",
        "    # Step 7: Select top similar users as a group\n",
        "    similar_users_group = select_top_similar_users(cluster_data, group_size)\n",
        "\n",
        "    # Create the 'Groups' directory if it doesn't exist\n",
        "    os.makedirs('Groups', exist_ok=True)\n",
        "\n",
        "    # Save the output CSV file to the 'Groups' directory\n",
        "    similar_users_group.to_csv('Groups/Group_data.csv')\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtn8zezWUOOv",
        "outputId": "915785a0-435d-4a1b-d8d0-b6ccbb3d6d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-fuzzy\n",
            "  Downloading scikit-fuzzy-0.4.2.tar.gz (993 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/994.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/994.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/994.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m993.3/994.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m994.0/994.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.11.4)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (3.3)\n",
            "Building wheels for collected packages: scikit-fuzzy\n",
            "  Building wheel for scikit-fuzzy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-fuzzy: filename=scikit_fuzzy-0.4.2-py3-none-any.whl size=894078 sha256=9cab86c50b0ec6195f16840a84b72dbd7ebae057e45f4d9cac67f6a15f7ede86\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/86/1b/dfd97134a2c8313e519bcebd95d3fedc7be7944db022094bc8\n",
            "Successfully built scikit-fuzzy\n",
            "Installing collected packages: scikit-fuzzy\n",
            "Successfully installed scikit-fuzzy-0.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGpvR2Yqhn6l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import skfuzzy as fuzz\n",
        "from scipy.stats import pearsonr\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjaE2wt1hpCq"
      },
      "outputs": [],
      "source": [
        "def read_dataset(dataset_path):\n",
        "    return pd.read_csv(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksK1-OlchpMu"
      },
      "outputs": [],
      "source": [
        "def calculate_preference(user_id, data):\n",
        "    user_data = data[data['User.ID'] == user_id]\n",
        "    if user_data.empty:\n",
        "        return None  # Return None if user ID not found in the dataset\n",
        "\n",
        "    # Columns containing ratings\n",
        "    rating_columns = ['Value.Rating', 'Rooms.Rating', 'Location.Rating', 'Cleanliness.Rating',\n",
        "                      'Front.Desk.Rating', 'Service.Rating', 'Business.Service.Rating']\n",
        "\n",
        "    # Average ratings\n",
        "    average_ratings = data[rating_columns].mean()\n",
        "\n",
        "    # User's ratings\n",
        "    user_ratings = user_data[rating_columns].iloc[0]\n",
        "\n",
        "    # Calculate preferences\n",
        "    preferences = average_ratings - user_ratings\n",
        "\n",
        "    return preferences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VGZmDL4hpN_"
      },
      "outputs": [],
      "source": [
        "def normalize_preferences(preferences):\n",
        "    # Normalize the preferences using Min-Max scaling\n",
        "    min_pref = np.min(preferences)\n",
        "    max_pref = np.max(preferences)\n",
        "    return (preferences - min_pref) / (max_pref - min_pref)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ0KOYsXhpTC"
      },
      "outputs": [],
      "source": [
        "def perform_fuzzy_cmeans_clustering(normalized_preferences, c, m, max_iter):\n",
        "    # FCM clustering\n",
        "    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
        "        data=normalized_preferences.T, c=c, m=m, error=0.01, maxiter=max_iter, init=None\n",
        "    )\n",
        "\n",
        "    # Assign cluster labels to users\n",
        "    cluster_membership = np.argmax(u, axis=0)\n",
        "    return cluster_membership"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTJ9tYnQhpUa"
      },
      "outputs": [],
      "source": [
        "def filter_users_by_cluster(preferences, cluster_membership, target_cluster):\n",
        "    # Combine the user-item matrix with cluster labels\n",
        "    cluster_labaled_preferences = pd.concat([preferences, pd.DataFrame(cluster_membership, index=preferences.index, columns=[\"Cluster Label\"])], axis=1)\n",
        "\n",
        "    # Filter users from the target cluster\n",
        "    cluster_data = cluster_labaled_preferences[cluster_labaled_preferences[\"Cluster Label\"] == target_cluster]\n",
        "\n",
        "    # Delete the \"Cluster Label\" column\n",
        "    del cluster_data[\"Cluster Label\"]\n",
        "\n",
        "    return cluster_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-yAIL6NhpZB"
      },
      "outputs": [],
      "source": [
        "def calculate_pcc(user1_preferences, user2_preferences):\n",
        "    # Convert to numpy arrays\n",
        "    x = np.array(user1_preferences)\n",
        "    y = np.array(user2_preferences)\n",
        "\n",
        "    # Calculate Pearson correlation coefficient\n",
        "    return pearsonr(x, y)[0] if len(x) == len(y) else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ciNOIvMhpah"
      },
      "outputs": [],
      "source": [
        "    # Calculate PCC with the randomly selected user for all users in the same cluster\n",
        "    pcc_values = []\n",
        "\n",
        "    for user_id in cluster_data.index.unique():\n",
        "        if user_id != random_user:\n",
        "            user1_preferences = cluster_data.loc[random_user]\n",
        "            user2_preferences = cluster_data.loc[user_id]\n",
        "\n",
        "            pcc = calculate_pcc(user1_preferences, user2_preferences)\n",
        "            if pcc is not None:\n",
        "                pcc_values.append((user_id, pcc))\n",
        "\n",
        "    # Sort users by PCC values in descending order\n",
        "    pcc_values.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Extract the user IDs of the top similar users\n",
        "    similar_user_ids = [user_id for user_id, _ in pcc_values][:group_size]\n",
        "\n",
        "    # Create a new DataFrame containing data of the top similar users as a group\n",
        "    group_data = cluster_data.loc[similar_user_ids]\n",
        "\n",
        "    return group_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "tmsw5h81hpeS",
        "outputId": "b2f755e8-87fe-49e1-c35e-926dc6e60828"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'fuzz' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-9458d2500c19>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-9458d2500c19>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(dataset_path, target_cluster, group_size, c, m, max_iter)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Step 5: Perform Fuzzy C-Means Clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mcluster_membership\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_fuzzy_cmeans_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_preferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Step 6: Filter users by cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-1d0e41e9a234>\u001b[0m in \u001b[0;36mperform_fuzzy_cmeans_clustering\u001b[0;34m(normalized_preferences, c, m, max_iter)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperform_fuzzy_cmeans_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_preferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# FCM clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalized_preferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fuzz' is not defined"
          ]
        }
      ],
      "source": [
        "# Main function to orchestrate the entire process\n",
        "def main(dataset_path='/content/TripAdvisor_Filled.csv', target_cluster=1, group_size=5, c=3, m=50, max_iter=1000):\n",
        "    # Step 1: Read the dataset\n",
        "    data = read_dataset(dataset_path)\n",
        "\n",
        "    # Step 2: Get unique user IDs\n",
        "    unique_user_ids = data['User.ID'].unique()\n",
        "\n",
        "    # Step 3: Calculate preferences for each user\n",
        "    preferences = {}\n",
        "    for user_id in unique_user_ids:\n",
        "        pref = calculate_preference(user_id, data)\n",
        "        if pref is not None:\n",
        "            preferences[user_id] = pref\n",
        "    preferences_df = pd.DataFrame.from_dict(preferences, orient='index')\n",
        "\n",
        "    # Step 4: Normalize preferences\n",
        "    normalized_preferences = normalize_preferences(preferences_df)\n",
        "\n",
        "    # Step 5: Perform Fuzzy C-Means Clustering\n",
        "    cluster_membership = perform_fuzzy_cmeans_clustering(normalized_preferences, c, m, max_iter)\n",
        "\n",
        "    # Step 6: Filter users by cluster\n",
        "    cluster_data = filter_users_by_cluster(preferences_df, cluster_membership, target_cluster)\n",
        "\n",
        "    # Step 7: Select top similar users as a group\n",
        "    similar_users_group = select_top_similar_users(cluster_data, group_size)\n",
        "\n",
        "    # Create the 'Groups' directory if it doesn't exist\n",
        "    os.makedirs('Groups', exist_ok=True)\n",
        "\n",
        "    # Save the output CSV file to the 'Groups' directory\n",
        "    similar_users_group.to_csv('Groups/Group_data.csv')\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dM__Y5thpgL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial import distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7O0zO0phpjM"
      },
      "outputs": [],
      "source": [
        "def calculate_trust(Group):\n",
        "    members = Group.index\n",
        "    no_member = len(members)\n",
        "\n",
        "    Trust_matrix = pd.DataFrame(0.0, index=members, columns=members)\n",
        "\n",
        "    for u in members:\n",
        "        rated_list_u = Group.loc[u].index[Group.loc[u] > 0]\n",
        "        count_rated_u = len(rated_list_u)\n",
        "        ratings_u = Group.loc[u][:]\n",
        "\n",
        "        if count_rated_u == 0:\n",
        "            continue  # Skip if there are no rated items for user u\n",
        "\n",
        "        for v in members:\n",
        "            if u == v:\n",
        "                continue\n",
        "\n",
        "            rated_list_v = Group.loc[v].index[Group.loc[v] > 0]\n",
        "            count_rated_v = len(rated_list_v)\n",
        "            ratings_v = Group.loc[v][:]\n",
        "\n",
        "            intersection_uv = set(rated_list_u).intersection(rated_list_v)\n",
        "            count_intersection = len(intersection_uv)\n",
        "\n",
        "            partnership_uv = count_intersection / count_rated_u\n",
        "\n",
        "            dst_uv = 1 / (1 + distance.euclidean(ratings_u, ratings_v))\n",
        "\n",
        "            trust_uv = (2 * partnership_uv * dst_uv) / (partnership_uv + dst_uv)\n",
        "            Trust_matrix.at[u, v] = trust_uv\n",
        "\n",
        "    return Trust_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgDGdKvGhplA"
      },
      "outputs": [],
      "source": [
        "def calculate_similarity(Group):\n",
        "    members = Group.index\n",
        "    ratings = Group.to_numpy()  # Convert DataFrame to a NumPy array\n",
        "\n",
        "    # Calculate the Pearson correlation coefficient similarity\n",
        "    PCC = np.corrcoef(ratings, rowvar=True)\n",
        "\n",
        "    # Convert the matrix to a DataFrame with proper index and columns\n",
        "    PCC_df = pd.DataFrame(PCC, index=members, columns=members)\n",
        "\n",
        "    return PCC_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdIuGqtihpov"
      },
      "outputs": [],
      "source": [
        "# Function to identify leader within a group based on Trust and Similarity matrices\n",
        "def identify_leader(Trust_matrix, Similarity_matrix, total_members):\n",
        "\n",
        "    trust_sum = np.sum(Trust_matrix.values, axis=0) - 1\n",
        "    similarity_sum = np.sum(Similarity_matrix.values, axis=0) - 1\n",
        "    ts_sumation = trust_sum + similarity_sum\n",
        "\n",
        "    LeaderId = np.argmax(ts_sumation)\n",
        "    LeaderImpact = ts_sumation[LeaderId] / (total_members - 1)\n",
        "    print(LeaderId)\n",
        "    return Trust_matrix.index[LeaderId], LeaderImpact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDN6yYZphpqd"
      },
      "outputs": [],
      "source": [
        "# Function to calculate influence weight based on leader's impact, similarity, and trust\n",
        "def calculate_influence_weight(leader_id, leader_impact, similarity_uv, trust_uv, v):\n",
        "\n",
        "    if v == leader_id:\n",
        "        weight_uv = (1/2) * ((leader_impact + (similarity_uv * trust_uv)) / (similarity_uv + trust_uv))\n",
        "    else:\n",
        "        weight_uv = (similarity_uv * trust_uv) / (similarity_uv + trust_uv)\n",
        "\n",
        "    return weight_uv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk3x6Jx4hpt1"
      },
      "outputs": [],
      "source": [
        "def influenced_rating(group):\n",
        "\n",
        "    members = group.index\n",
        "    movies = group.columns\n",
        "    num_members, num_items = len(members), len(movies)\n",
        "\n",
        "    # Calculate trust and similarity matrices\n",
        "    trust_matrix = calculate_trust(group)\n",
        "    similarity_matrix = calculate_similarity(group)\n",
        "\n",
        "    # Identify the leader and their impact\n",
        "    leader_id, leader_impact = identify_leader(trust_matrix, similarity_matrix, num_members)\n",
        "\n",
        "    influenced_ratings = pd.DataFrame(0.0, index=members, columns=movies)\n",
        "\n",
        "    for u in members:\n",
        "        for i in movies:\n",
        "            score_ui = group.at[u, i]\n",
        "            influence = 0\n",
        "\n",
        "            if score_ui > 0:\n",
        "                for v in members:\n",
        "                    if v != u:\n",
        "                        score_vi = group.at[v, i]\n",
        "                        similarity_uv = similarity_matrix.at[u, v]\n",
        "                        trust_uv = trust_matrix.at[u, v]\n",
        "                        weight_vu = calculate_influence_weight(leader_id, leader_impact, similarity_uv, trust_uv, v)\n",
        "\n",
        "                        if score_vi > 0:\n",
        "                            influence += weight_vu * (score_vi - score_ui)\n",
        "\n",
        "                influenced_ratings.at[u, i] = score_ui + influence\n",
        "\n",
        "    return influenced_ratings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQyt85ezhpvf"
      },
      "outputs": [],
      "source": [
        "def evaluate_recommendations(Group, Group_Rating, rec_size, satisfied_Tr):\n",
        "\n",
        "    Group_Rating = Group_Rating.sort_values(ascending=False)\n",
        "    rec_list = Group_Rating[Group_Rating != 0]\n",
        "\n",
        "    recommendation_index = rec_list.index\n",
        "    members = Group.index\n",
        "    no_member = len(members)\n",
        "\n",
        "    TP = TN = FP = FN = 0\n",
        "    satisfied = 1\n",
        "\n",
        "    for r, index in enumerate(recommendation_index):\n",
        "        for u in members:\n",
        "            preference_u_ind = Group.at[u, index]\n",
        "\n",
        "            if r < rec_size:\n",
        "                if preference_u_ind >= satisfied_Tr:\n",
        "                    satisfied += 1\n",
        "                    TP += 1\n",
        "                else:\n",
        "                    FP += 1\n",
        "            else:\n",
        "                if preference_u_ind >= satisfied_Tr:\n",
        "                    FN += 1\n",
        "                else:\n",
        "                    TN += 1\n",
        "\n",
        "    total_count = TP + FP + TN + FN\n",
        "\n",
        "    accuracy = ((TP + TN) / total_count) * 100 if total_count > 0 else 0\n",
        "    precision = (TP / (TP + FP)) * 100 if TP + FP > 0 else 0\n",
        "    recall = (TP / (TP + FN)) * 100 if TP + FN > 0 else 0\n",
        "    specificity = (TN / (TN + FP)) * 100 if TN + FP > 0 else 0\n",
        "    f1_score = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "    balanced_accuracy = (specificity + recall) / 2\n",
        "\n",
        "    results = {\n",
        "        \"Satisfaction\": satisfied / (no_member * rec_size),\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"Specificity\": specificity,\n",
        "        \"Balanced_Accuracy\": balanced_accuracy,\n",
        "        \"F1_Score\": f1_score,\n",
        "        \"Confusion_counters\": {\"TP\": TP, \"FP\": FP, \"TN\": TN, \"FN\": FN}\n",
        "    }\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c_zF9Cdhpzp",
        "outputId": "37633fdd-8d90-4135-d25a-b398effc9900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "Leader ID: gomezaddams\n",
            "Evaluation Results: {'Satisfaction': 0.2, 'Accuracy': 50.0, 'Precision': 0.0, 'Recall': 0, 'Specificity': 50.0, 'Balanced_Accuracy': 25.0, 'F1_Score': 0, 'Confusion_counters': {'TP': 0, 'FP': 5, 'TN': 5, 'FN': 0}}\n"
          ]
        }
      ],
      "source": [
        "# Main function to execute the recommendation system\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to execute the group recommendation system.\n",
        "\n",
        "    Reads group ratings from a CSV file, calculates influenced ratings, evaluates recommendations,\n",
        "    and prints the evaluation results.\n",
        "    \"\"\"\n",
        "    Group = pd.read_csv('/content/grouped data.csv')\n",
        "\n",
        "    users_id = Group[\"Unnamed: 0\"].unique()\n",
        "    Group = Group.drop(['Unnamed: 0'], axis=1)\n",
        "    Group = Group.set_axis(users_id, axis='rows')\n",
        "\n",
        "    # Calculate members' influenced ratings\n",
        "    Influenced_Ratings = influenced_rating(Group)\n",
        "\n",
        "    # Determine group rating for items using averaging aggregation method\n",
        "    Group_Rating = Influenced_Ratings.mean(axis=0).fillna(0)\n",
        "\n",
        "    # Identify the leader and their impact\n",
        "    trust_matrix = calculate_trust(Group)\n",
        "    similarity_matrix = calculate_similarity(Group)\n",
        "    total_members = len(Group)\n",
        "    leader_id, leader_impact = identify_leader(trust_matrix, similarity_matrix, total_members)\n",
        "\n",
        "    # Evaluate the recommendations\n",
        "    rec_size = 1\n",
        "    satisfied_Tr = 3\n",
        "    Evaluation_Results = evaluate_recommendations(Group, Group_Rating, rec_size, satisfied_Tr)\n",
        "\n",
        "    print(\"Leader ID:\", leader_id)\n",
        "    print(\"Evaluation Results:\", Evaluation_Results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIKye_HPhp1c",
        "outputId": "d35aa2dd-e0f5-443e-ad20-cd9851c367e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement skifuzzy (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for skifuzzy\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install skifuzzy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7is3xkm5hp4t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSid559yhp6d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCFVKEVYhp-h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLCrSnl8hqBK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKqOotuAhqD1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAvhf_VOhqFJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VyKmt3jhqI3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5GcVofmhqKi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vskcUoGhqOo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3myRczcYhqQU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnAXqYxHhqUP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0wukZrghqV8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rJ7Qq-EhqZs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBGpNdJthqbY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1aYhZGahqfA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmf61IxWhqgq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV0KIyxjhqi3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBlUYG80hqk_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ufF46pIhqok"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84Q78uNXhqqZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PybSYMefhqub"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTSvN9SThq0Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXi73Ffq1QsgZ+xzvK2ppA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}